{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg2F89eGROepucKMAj+6nS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absolution-end/Learn_Neural_Networking/blob/main/basic_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sentences =[\"I love cats\",\"i love dogs\",\"I love Girls\"]"
      ],
      "metadata": {
        "id": "vkgSQzOX7rm6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n"
      ],
      "metadata": {
        "id": "csXW33R69ycM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the vocabulary\n",
        "vectorize_layer.adapt(sentences)"
      ],
      "metadata": {
        "id": "ixA3f43g91Zi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary list. Ignore special tokens for now.\n",
        "vocabulary = vectorize_layer.get_vocabulary(include_special_tokens=False)"
      ],
      "metadata": {
        "id": "qSMfXy9p95sL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the token index\n",
        "for index, word in enumerate(vocabulary):\n",
        "  print(index, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-_z_aOr-ABf",
        "outputId": "d36e6f21-7344-4be4-e0b0-f70804c1a60c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 love\n",
            "1 i\n",
            "2 girls\n",
            "3 dogs\n",
            "4 cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_sent= 'Love is forever'\n",
        "sent = vectorize_layer(prompt_sent)\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvDg9v19VAgN",
        "outputId": "1085626d-04e2-4d04-e65b-3e7c1c0b3ea9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 1 1], shape=(3,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add another input\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!',\n",
        "    'How the fuck is you'\n",
        "]\n",
        "\n",
        "# Initialize the layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization()\n",
        "\n",
        "# Build the vocabulary\n",
        "vectorize_layer.adapt(sentences)\n",
        "\n",
        "# Get the vocabulary list. Ignore special tokens for now.\n",
        "vocabulary = vectorize_layer.get_vocabulary(include_special_tokens=False)"
      ],
      "metadata": {
        "id": "v4ugNb67-P-q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the token index\n",
        "for index, word in enumerate(vocabulary):\n",
        "  print(index, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSCKwLP7-dCR",
        "outputId": "23a2129a-4ecd-43bc-f83e-e02498335a57"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 my\n",
            "1 love\n",
            "2 you\n",
            "3 i\n",
            "4 dog\n",
            "5 the\n",
            "6 is\n",
            "7 how\n",
            "8 fuck\n",
            "9 cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary list.\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "# Print the token index\n",
        "for index, word in enumerate(vocabulary):\n",
        "  print(index, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p12PdcI-iEP",
        "outputId": "07964108-473f-4b66-83f6-1e76a47114a2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            "1 [UNK]\n",
            "2 my\n",
            "3 love\n",
            "4 you\n",
            "5 i\n",
            "6 dog\n",
            "7 the\n",
            "8 is\n",
            "9 how\n",
            "10 fuck\n",
            "11 cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So here we are just taking input string and assigning it a number\n",
        "# String input\n",
        "sample_input = ['I love my dog','Good people build butiful girls']\n",
        "\n",
        "# Convert the string input to an integer sequence\n",
        "sequence = vectorize_layer(sample_input)\n",
        "\n",
        "# Print the result\n",
        "print(sequence)"
      ],
      "metadata": {
        "id": "5rh23Cep_Hpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c731026-2405-4df3-a70e-3ecd1b3e543e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[5 3 2 6 0]\n",
            " [1 1 1 1 1]], shape=(2, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To assign a number we can use more efficinet thing which is to use #map()- function\n",
        "# Convert the list to tf.data.Dataset\n",
        "sentences_dataset = tf.data.Dataset.from_tensor_slices(sentences)\n",
        "\n",
        "# Define a maping function to convert each sample input\n",
        "sequences = sentences_dataset.map(vectorize_layer)\n",
        "\n",
        "# print the integer sequence\n",
        "for sentence, sequence in zip(sentences_dataset, sequence):\n",
        "  print(f\"{sentences} ----> {sequence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX_Vs2d0ViT3",
        "outputId": "5c9eff89-4aa2-42e4-b867-dc88a9e7822d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i love my dog', 'I, love my cat', 'You love my dog!', 'How the fuck is you'] ----> 9\n",
            "['i love my dog', 'I, love my cat', 'You love my dog!', 'How the fuck is you'] ----> 7\n",
            "['i love my dog', 'I, love my cat', 'You love my dog!', 'How the fuck is you'] ----> 10\n",
            "['i love my dog', 'I, love my cat', 'You love my dog!', 'How the fuck is you'] ----> 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the layer to the string input list\n",
        "sequences_post = vectorize_layer(sentences)\n",
        "\n",
        "# Print the results\n",
        "print('INPUT:')\n",
        "print(sentences)\n",
        "print()\n",
        "\n",
        "print('OUTPUT:')\n",
        "print(sequences_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGOLAKjmlqm4",
        "outputId": "2ec362e2-0865-4cbf-a8ce-38c11ba7a959"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT:\n",
            "['i love my dog', 'I, love my cat', 'You love my dog!', 'How the fuck is you']\n",
            "\n",
            "OUTPUT:\n",
            "tf.Tensor(\n",
            "[[ 5  3  2  6  0]\n",
            " [ 5  3  2 11  0]\n",
            " [ 4  3  2  6  0]\n",
            " [ 9  7 10  8  4]], shape=(4, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is the code for pre padding sequence to uniform length\n",
        "sequence_pre = tf.keras.utils.pad_sequences(sequences, padding= 'pre')\n",
        "print(sequence_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLofHRyam7eh",
        "outputId": "9cb39f55-8b77-41c9-8775-b5b6fdc4aa70"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  5  3  2  6]\n",
            " [ 0  5  3  2 11]\n",
            " [ 0  4  3  2  6]\n",
            " [ 9  7 10  8  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  To pad the sequence and the limit the size we can use maxlen in the same function\n",
        "sequences_post_trunc = tf.keras.utils.pad_sequences(sequences, maxlen=5, padding='pre')\n",
        "\n",
        "# Print the results\n",
        "print('INPUT:')\n",
        "[print(sequence.numpy()) for sequence in sequences]\n",
        "print()\n",
        "\n",
        "print('OUTPUT:')\n",
        "print(sequences_post_trunc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su75u4Jtpx-s",
        "outputId": "a9fc94c4-058e-4c28-f47f-1954523eec35"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT:\n",
            "[5 3 2 6]\n",
            "[ 5  3  2 11]\n",
            "[4 3 2 6]\n",
            "[ 9  7 10  8  4]\n",
            "\n",
            "OUTPUT:\n",
            "[[ 0  5  3  2  6]\n",
            " [ 0  5  3  2 11]\n",
            " [ 0  4  3  2  6]\n",
            " [ 9  7 10  8  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another what to padd the sentences is to set the TextVector to ragged.\n",
        "vectorization_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
        "\n",
        "vector_layer = vectorization_layer.adapt(sentences)\n",
        "\n",
        "ragged_sentences = vectorization_layer(sentences)\n",
        "print(ragged_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1IBT-6gs8y2",
        "outputId": "89b25035-6a07-42dc-a0f5-c3a9a407a1fa"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[5, 3, 2, 6], [5, 3, 2, 11], [4, 3, 2, 6], [9, 7, 10, 8, 4]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_pre = tf.keras.utils.pad_sequences(ragged_sentences.numpy(), maxlen=4)\n",
        "print(seq_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p6ZUB60uvMf",
        "outputId": "b0ee46d9-91aa-457a-8038-c12028fe7c52"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  3  2  6]\n",
            " [ 5  3  2 11]\n",
            " [ 4  3  2  6]\n",
            " [ 7 10  8  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with words that are not in the vocabulary\n",
        "sentences_with_oov = [\n",
        "    'i really love my dog',\n",
        "    'my dog loves my manatee'\n",
        "]\n",
        "\n",
        "# Generate the sequences\n",
        "sequences_with_oov = vectorize_layer(sentences_with_oov)\n",
        "\n",
        "# Print the integer sequences\n",
        "for sentence, sequence in zip(sentences_with_oov, sequences_with_oov):\n",
        "  print(f'{sentence} ---> {sequence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD_Bd5vivmWh",
        "outputId": "52cdb3bd-f3cf-4f92-a998-02598f4162ac"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i really love my dog ---> [5 1 3 2 6]\n",
            "my dog loves my manatee ---> [2 6 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmpH9jrgwMUR",
        "outputId": "58a34b01-6556-4504-a328-1b143fac5be8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 18:22:14--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.207, 173.194.79.207, 108.177.96.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘sarcasm.json’\n",
            "\n",
            "sarcasm.json        100%[===================>]   5.38M  7.16MB/s    in 0.8s    \n",
            "\n",
            "2025-02-08 18:22:16 (7.16 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import json\n",
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "ioFi4ToVypkm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the json file\n",
        "with open('/content/sarcasm.json','r') as f:\n",
        "  datastore =json.load(f)"
      ],
      "metadata": {
        "id": "409Xjn4UzoAj"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-sarcastic headline\n",
        "print(datastore[0])\n",
        "\n",
        "# Sarcastic headline\n",
        "print(datastore[20000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uVRPbcB1lFb",
        "outputId": "32b9ed36-16f6-4be7-bee5-78a55af15312"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n",
            "{'article_link': 'https://www.theonion.com/pediatricians-announce-2011-newborns-are-ugliest-babies-1819572977', 'headline': 'pediatricians announce 2011 newborns are ugliest babies in 30 years', 'is_sarcastic': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(item['headline'] for item in datastore)"
      ],
      "metadata": {
        "id": "VPDtpLUt1lk_"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
        "vec_layer.adapt(sentences)\n",
        "\n",
        "post_padded_sequence = vec_layer(sentences)\n",
        "print(post_padded_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ZgTjWr2fvW",
        "outputId": "00c7e670-b119-432f-f3d6-979bc805f6d2"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[295, 15335, 801, 3788, 2264, 48, 362, 93, 2225, 6, 2578, 8719],\n",
            " [4, 8793, 3353, 2845, 28, 2, 156, 8515, 394, 2957, 6, 244, 9, 951],\n",
            " [140, 825, 2, 813, 1100, 2048, 571, 5057, 199, 139, 39, 46, 2, 13050],\n",
            " ..., [8862, 9, 66], [1832, 377, 3857, 5780, 866, 1665, 4618, 3546],\n",
            " [23100, 1692, 6, 4, 23598, 843]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a sample headline and sequence\n",
        "index = 2\n",
        "print(f'sample headline: {sentences[index]}')\n",
        "print(f'padded sequence: {post_padded_sequence[index]}')\n",
        "print()\n",
        "\n",
        "# Print dimensions of padded sequences\n",
        "print(f'shape of padded sequences: {post_padded_sequence.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2puJtdxK3FR5",
        "outputId": "82b90806-978d-43fd-d05c-d91a2088e010"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050]\n",
            "\n",
            "shape of padded sequences: (26709, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ragged_sequences = vectorize_layer(sentences)"
      ],
      "metadata": {
        "id": "6OIOce-T3u2y"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply pre-padding to the ragged tensor\n",
        "pre_padded_sequences = pad_sequences(ragged_sequences.numpy())\n",
        "\n",
        "# Preview the result for the 2nd sequence\n",
        "pre_padded_sequences[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQx9m-re4j4N",
        "outputId": "415020cd-bd2e-44db-b57e-0bb8cbca0553"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a sample headline and sequence\n",
        "index = 2\n",
        "print(f'sample headline: {sentences[index]}')\n",
        "print()\n",
        "print(f'post-padded sequence: {post_padded_sequence[index]}')\n",
        "print()\n",
        "print(f'pre-padded sequence: {pre_padded_sequences[index]}')\n",
        "print()\n",
        "\n",
        "# Print dimensions of padded sequences\n",
        "print(f'shape of post-padded sequences: {post_padded_sequence.shape}')\n",
        "print(f'shape of pre-padded sequences: {pre_padded_sequences.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joXXn-0T4mkH",
        "outputId": "26e90fa8-fde1-4eea-a8b7-3a2211f97e4a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "\n",
            "post-padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
            "     2 13050]\n",
            "\n",
            "pre-padded sequence: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n",
            "\n",
            "shape of post-padded sequences: (26709, None)\n",
            "shape of pre-padded sequences: (26709, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuEOQpUf4z1D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}